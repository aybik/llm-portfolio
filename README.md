# ğŸ¤– Large Language Models Portfolio

A comprehensive collection of LLM projects, implementations, and experiments showcasing practical applications of modern language models, RAG systems, and AI agents.

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)](https://langchain.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-API-412991.svg)](https://openai.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Projects](#projects)
- [Technical Stack](#technical-stack)
- [Installation](#installation)
- [Repository Structure](#repository-structure)
- [Usage Examples](#usage-examples)
- [Key Learnings](#key-learnings)
- [Future Roadmap](#future-roadmap)
- [Contributing](#contributing)
- [Contact](#contact)

## ğŸ¯ Overview

This repository contains hands-on implementations and experiments with Large Language Models, covering everything from fundamental concepts to production-ready applications. Each project demonstrates practical problem-solving using state-of-the-art LLM technologies.

**Key Focus Areas:**
- ğŸ” Retrieval-Augmented Generation (RAG)
- ğŸ”— LangChain & LangGraph workflows
- ğŸ’¬ Conversational AI & Chatbots
- ğŸ“Š Semantic Search & Vector Databases
- ğŸ¯ Prompt Engineering & Optimization
- ğŸ¤– AI Agents & Tool Integration

## ğŸš€ Projects

### 1. RAG Systems

#### **Document Q&A with Semantic Search**
Advanced RAG implementation using vector databases for intelligent document retrieval and question answering.

**Technologies:** LangChain, ChromaDB/Qdrant, OpenAI Embeddings, FAISS
**Features:**
- Multi-document ingestion and chunking strategies
- Hybrid search (semantic + keyword)
- Context-aware answer generation
- Source attribution and citation

ğŸ“‚ Location: `projects/rag-systems/`

#### **Conversational RAG with Memory**
Enhanced RAG system with conversation history and context management.

**Technologies:** LangChain, Vector Stores, Memory Management
**Features:**
- Persistent conversation memory
- Follow-up question handling
- Context window optimization
- Multi-turn dialogue support

ğŸ“‚ Location: `projects/rag-systems/conversational-rag/`

---

### 2. LangChain Applications

#### **Multi-Agent System**
Coordinated AI agents working together to solve complex tasks.

**Technologies:** LangChain, LangGraph, Agent Tools
**Features:**
- Task decomposition and delegation
- Tool-augmented agents (web search, calculator, etc.)
- Agent orchestration and communication
- Error handling and retry logic

ğŸ“‚ Location: `projects/langchain-apps/multi-agent/`

#### **Custom Chain Architectures**
Various LangChain implementations for different use cases.

**Technologies:** LangChain, Custom Chains, Prompt Templates
**Examples:**
- Sequential chains for multi-step reasoning
- Router chains for dynamic task routing
- MapReduce chains for document summarization
- Transform chains for data processing

ğŸ“‚ Location: `projects/langchain-apps/custom-chains/`

---

### 3. Prompt Engineering

#### **Prompt Optimization Framework**
Systematic approach to crafting and testing prompts for optimal results.

**Features:**
- Prompt templates library
- A/B testing framework
- Performance metrics tracking
- Best practices documentation

ğŸ“‚ Location: `projects/prompt-engineering/`

#### **Few-Shot Learning Examples**
Collection of effective few-shot prompting strategies across domains.

**Domains:**
- Code generation
- Data extraction
- Text classification
- Creative writing

ğŸ“‚ Location: `projects/prompt-engineering/few-shot/`

---

### 4. Vector Databases & Embeddings

#### **Embedding Comparison Study**
Performance analysis of different embedding models and vector databases.

**Technologies:** OpenAI, Cohere, Sentence-Transformers, ChromaDB, Qdrant, Pinecone
**Metrics:**
- Retrieval accuracy
- Query latency
- Storage efficiency
- Cost analysis

ğŸ“‚ Location: `projects/vector-databases/`

---

### 5. Production Applications

#### **Intelligent Chatbot**
Production-ready chatbot with enterprise features.

**Technologies:** FastAPI, Streamlit, LangChain, Docker
**Features:**
- REST API endpoints
- Web UI interface
- User authentication
- Conversation persistence
- Rate limiting
- Logging and monitoring

ğŸ“‚ Location: `projects/production-apps/chatbot/`

## ğŸ›  Technical Stack

### **Core Technologies**
- **Languages:** Python 3.9+
- **LLM Providers:** OpenAI, Anthropic, HuggingFace
- **Frameworks:** LangChain, LangGraph, Haystack
- **Vector Databases:** ChromaDB, Qdrant, Pinecone, FAISS
- **Web Frameworks:** FastAPI, Streamlit, Gradio

### **Key Libraries**
```
langchain>=0.1.0
openai>=1.0.0
chromadb>=0.4.0
qdrant-client>=1.6.0
sentence-transformers>=2.2.0
faiss-cpu>=1.7.4
tiktoken>=0.5.0
streamlit>=1.28.0
fastapi>=0.104.0
```

## ğŸ“¦ Installation

### Prerequisites
- Python 3.9 or higher
- pip or poetry package manager
- API keys (OpenAI, Anthropic, etc.)

### Quick Start

```bash
# Clone the repository
git clone https://github.com/aybik/llm-portfolio.git
cd llm-portfolio

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys

# Run example project
cd projects/rag-systems
python document_qa.py
```

### Using Poetry (Recommended)

```bash
# Install dependencies with Poetry
poetry install

# Activate virtual environment
poetry shell

# Run any project
poetry run python projects/rag-systems/document_qa.py
```

## ğŸ“ Repository Structure

```
llm-portfolio/
â”œâ”€â”€ projects/
â”‚   â”œâ”€â”€ rag-systems/
â”‚   â”‚   â”œâ”€â”€ document_qa/
â”‚   â”‚   â”œâ”€â”€ conversational_rag/
â”‚   â”‚   â””â”€â”€ hybrid_search/
â”‚   â”œâ”€â”€ langchain-apps/
â”‚   â”‚   â”œâ”€â”€ multi-agent/
â”‚   â”‚   â”œâ”€â”€ custom-chains/
â”‚   â”‚   â””â”€â”€ tools-integration/
â”‚   â”œâ”€â”€ prompt-engineering/
â”‚   â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ optimization/
â”‚   â”‚   â””â”€â”€ few-shot/
â”‚   â”œâ”€â”€ vector-databases/
â”‚   â”‚   â”œâ”€â”€ embeddings-comparison/
â”‚   â”‚   â””â”€â”€ performance-benchmarks/
â”‚   â””â”€â”€ production-apps/
â”‚       â”œâ”€â”€ chatbot/
â”‚       â””â”€â”€ api-service/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_llm_fundamentals.ipynb
â”‚   â”œâ”€â”€ 02_langchain_basics.ipynb
â”‚   â”œâ”€â”€ 03_rag_implementation.ipynb
â”‚   â”œâ”€â”€ 04_prompt_engineering.ipynb
â”‚   â””â”€â”€ 05_advanced_techniques.ipynb
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ vector_stores.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â””â”€â”€ metrics.py
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ best-practices.md
â”‚   â””â”€â”€ tutorials/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ’¡ Usage Examples

### RAG System Example

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# Initialize components
embeddings = OpenAIEmbeddings()
vectorstore = Chroma(
    persist_directory="./chroma_db",
    embedding_function=embeddings
)

# Create RAG chain
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(temperature=0),
    chain_type="stuff",
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
)

# Query the system
response = qa_chain.run("What are the key findings in the document?")
print(response)
```

### Multi-Agent System Example

```python
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.llms import OpenAI

# Define tools
tools = [
    Tool(
        name="Search",
        func=search_tool,
        description="Search the web for current information"
    ),
    Tool(
        name="Calculator",
        func=calculator_tool,
        description="Perform mathematical calculations"
    )
]

# Initialize agent
agent = initialize_agent(
    tools,
    OpenAI(temperature=0),
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# Run agent
result = agent.run("What is the population of Berlin multiplied by 2?")
```

## ğŸ“ Key Learnings

### RAG Systems
- **Chunking Strategy:** Optimal chunk size depends on domain (500-1000 tokens for technical docs)
- **Retrieval Metrics:** Precision vs. recall tradeoff in semantic search
- **Context Window Management:** Techniques for handling long documents with limited context

### Prompt Engineering
- **Temperature Settings:** Lower (0.0-0.3) for factual, higher (0.7-1.0) for creative
- **Few-Shot Learning:** 3-5 examples provide optimal guidance
- **Chain-of-Thought:** Significantly improves reasoning on complex tasks

### Vector Databases
- **Embedding Models:** text-embedding-3-large offers best quality/cost ratio
- **Index Types:** HNSW for speed, IVF for memory efficiency
- **Hybrid Search:** Combining semantic + keyword search improves accuracy by 15-20%

### Production Considerations
- **Cost Optimization:** Caching, prompt compression reduce API costs by 40-60%
- **Latency:** Streaming responses improve perceived performance
- **Error Handling:** Retry logic with exponential backoff for API resilience

## ğŸ—º Future Roadmap

### Q1 2025
- [ ] Fine-tuning experiments with custom datasets
- [ ] Multi-modal RAG (text + images)
- [ ] Advanced agent architectures (ReAct, Plan-and-Execute)

### Q2 2025
- [ ] LLM evaluation framework
- [ ] Knowledge graph integration
- [ ] Edge deployment (GGUF, quantization)

### Q3 2025
- [ ] Agentic workflows for business processes
- [ ] LLM observability and monitoring
- [ ] Cost optimization techniques

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup

```bash
# Install development dependencies
poetry install --with dev

# Run tests
pytest tests/

# Run linting
black .
flake8 .
mypy .
```

## ğŸ“§ Contact

**Aybik** - [GitHub](https://github.com/aybik)

Project Link: [https://github.com/aybik/llm-portfolio](https://github.com/aybik/llm-portfolio)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT models and APIs
- LangChain community for excellent frameworks
- ChromaDB and Qdrant teams for vector database solutions
- All contributors and open-source projects that made this possible

---

**â­ If you find this repository useful, please consider giving it a star!**
